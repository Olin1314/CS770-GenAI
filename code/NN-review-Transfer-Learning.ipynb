{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d35276",
   "metadata": {},
   "source": [
    "# Transfer Learning in Computer Vision\n",
    "\n",
    "In this notebook, we will apply transfer learning for the CIFAR-10 classification task. CIFAR-10 dataset (https://www.cs.toronto.edu/~kriz/cifar.html) consists of 60000 32x32 color images in 10 classes (6000 images per class). There are 50000 training images and 10000 test images. We will use the VGG16 pretrained model which is trained on the ImageNet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a2a9f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57efe69",
   "metadata": {},
   "source": [
    "Let's load the CIFAR-10 dataset whic is included in keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6090526",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (vaild_X, valid_y) = K.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ef35e4",
   "metadata": {},
   "source": [
    "Below, we preprocess the train and validation sets. We preprocess the input images using the vgg16.preprocess_input function which converts images from RGB to BGR and then each color channel is zero-centered with respect to the ImageNet dataset (without scaling). We also convert the label column to categorical (one-hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "599a6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(X, Y):\n",
    "        X = X.astype('float32')\n",
    "        X_preprocessed = K.applications.vgg16.preprocess_input(X)\n",
    "        Y_preprocessed = K.utils.to_categorical(Y, 10)\n",
    "        return(X_preprocessed, Y_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8eb3337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,train_y = preprocess_input(Xt, Yt)\n",
    "vaild_X,valid_y = preprocess_input(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5a832a",
   "metadata": {},
   "source": [
    "Let's load the VGG16 model without the top classification layer, these layer are frozen so that we dont make changes to them as we train the model for our new task. The include_top parameter determines whether to include the 3 fully-connected layers at the top of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e1ed6fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = K.applications.vgg16.VGG16(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        pooling='avg',\n",
    "                                        input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5123f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_5   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859506e",
   "metadata": {},
   "source": [
    "We will add new custom top layers to this pretrained model and will train only those last layers. We will add a flatten layer, followed by a batchnormalization, followed by two dense layers and a dropout layer, and finally a softmax layer for classification. The number of units in the softmax layer will be equal to the number of classes (10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b760990a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,869,066\n",
      "Trainable params: 2,860,874\n",
      "Non-trainable params: 8,192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Extract the last layer from third block of vgg16 model\n",
    "last = base_model.get_layer('block3_pool').output\n",
    "# Add own new layers on top of it\n",
    "x = K.layers.Flatten()(last)\n",
    "x = K.layers.BatchNormalization()(x)\n",
    "x = K.layers.Dense(256, activation='relu')(x)\n",
    "x = K.layers.Dense(256, activation='relu')(x)\n",
    "x = K.layers.Dropout(0.6)(x)\n",
    "output_layer = K.layers.Dense(10, activation='softmax')(x)\n",
    "model = K.Model(base_model.input, output_layer)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e89c753",
   "metadata": {},
   "source": [
    "Before we retrain the model, we will freeze the vgg16 layers so that we don't retrain them (we only want to retrain our own newly added top layers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "332fe30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "     layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66170d",
   "metadata": {},
   "source": [
    "We will define a callback to periodically save the best model to disk. A callback is an object that can perform actions at various stages of training such as at the start or end of an epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1785a1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aring/opt/anaconda3/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "callback = []\n",
    "callback += [K.callbacks.ModelCheckpoint('cifar10.h5',save_best_only=True,mode='min')]\n",
    "LEARNING_RATE=1e-4\n",
    "model.compile(optimizer=K.optimizers.Adam(lr=LEARNING_RATE), loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "968c5584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 229s 586ms/step - loss: 1.3461 - accuracy: 0.5484 - val_loss: 0.7733 - val_accuracy: 0.7385\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 220s 560ms/step - loss: 0.8343 - accuracy: 0.7180 - val_loss: 0.6642 - val_accuracy: 0.7714\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 227s 581ms/step - loss: 0.6925 - accuracy: 0.7640 - val_loss: 0.6101 - val_accuracy: 0.7877\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 214s 548ms/step - loss: 0.6029 - accuracy: 0.7951 - val_loss: 0.5818 - val_accuracy: 0.7997\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 210s 538ms/step - loss: 0.5318 - accuracy: 0.8190 - val_loss: 0.5612 - val_accuracy: 0.8091\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 223s 571ms/step - loss: 0.4828 - accuracy: 0.8346 - val_loss: 0.5493 - val_accuracy: 0.8092\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 220s 564ms/step - loss: 0.4363 - accuracy: 0.8514 - val_loss: 0.5415 - val_accuracy: 0.8137\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 505s 1s/step - loss: 0.3889 - accuracy: 0.8678 - val_loss: 0.5450 - val_accuracy: 0.8128\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 513s 1s/step - loss: 0.3603 - accuracy: 0.8753 - val_loss: 0.5351 - val_accuracy: 0.8198\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 234s 599ms/step - loss: 0.3250 - accuracy: 0.8887 - val_loss: 0.5351 - val_accuracy: 0.8203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc1dfbeba30>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_X, y=train_y,\n",
    "              batch_size=128,\n",
    "              validation_data=(vaild_X, valid_y),\n",
    "              epochs=10, shuffle=True,\n",
    "              callbacks=callback,\n",
    "              verbose=1\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9773cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
